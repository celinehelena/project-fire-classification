# üî• Classifica√ß√£o Bin√°ria da Presen√ßa de Fogo em Imagens com Yolov11
Este reposit√≥rio tem por objetivo apresentar um projeto desenvolvido para a disciplina de gradua√ß√£o, Vis√£o Computacional, que consiste em aborda uma solu√ß√£o para a classifica√ß√£o da presen√ßa de fogo em imagens usando o YOLOv11.

## üìå Introdu√ß√£o
Em 2024, o Brasil registrou 278,3 mil focos de inc√™ndio, segundo o Inpe, que representa um aumento de 46,5%, em rela√ß√£o ao ano anterior. De modo que a detec√ß√£o precoce desses principios de inc√™ndio √© essencia para uma resposta r√°pida e eficaz, minimizando os danos causados. Para que isso aconte√ßa √© necess√°rio um monitoramento autom√°tico de inc√™ndio por meio de imagens. Nesse contexto, a aplica√ß√£o de solu√ß√µes baseadas em vis√£o computacional e aprendizado de m√°quina tem se mostrado eficiente para a detec√ß√£o precoce de focos de inc√™ndio em imagens capturadas por sat√©lites, c√¢meras fixas ou drones.

Este trabalho apresenta o desenvolvimento de um aplica√ß√£o de classifica√ß√£o de imagens que identifica a presen√ßa ou aus√™ncia de fogo, utilizando a arquitetura YOLOv11, um modelo especifico para classifica√ß√£o de imagens. O objetivo √© treinar esse modelo para classificar imagens em duas categorias: "fire" e "non_fire".

## ‚öôÔ∏è Desenvolvimento / T√©cnicas Utilizadas
Para a tarefa de classifica√ß√£o de imagens, foi usado o dataset "Fire Dataset", disponiblizado no Kaggle, contendo 999 imagens categorizadas em duas pastas: `fire_images` e `non_fire_images`. O processo teve inicio com o download da base de dados, organizando-o da maneira como o YOLO aceita, √© necess√°rio que esteja organizado em subpastas de treinamento, valida√ß√£o e teste. Com isso, o conjunto de dados original extra√≠dos do Kaggle foi dividio em tr√™s subconjuntos: treinamento (70%), valida√ß√£o (15%) e teste (15%). O gr√°fico mostra essa divis√£o.
<p align="center">
<img src="assets/distribution_dataset_img.png" alt="Gr√°fico de Distribui√ß√£o das Imagens no Dataset" width="450"/>
</p>

A base de dados foi dividida nos conjuntos de treino, valida√ß√£o e teste da seguinte forma:

| Classe     | Treino | Valida√ß√£o | Teste |
|------------|--------|-----------|-------|
| `fire`     | 528    | 113       | 114   |
| `non_fire` | 170    | 36        | 38    |

Assim como, as imagens passaram por um processo de pr√©-processamento em que foram automaticamente redimensionadas para 640x640 pixels, conforme o par√¢mento `imgsz`, e normalizadas com valores de pixel convertidos para o intervalo `[0,1]`, conforme exigido pelo pipeline da Ultralytics. Al√©m de t√©cnicas leves de data augmentation foram aplicadas automaticamente, como espelhamento horizontal aleat√≥rio, corte e altera√ß√µes no brilho e contraste, promovendo uma melhor capacidade de generaliza√ß√£o do modelo.

Como modelo adotou-se a arquitetura Yolov11 na sua configura√ß√£o pr√©-treinada voltada para a classifica√ß√£o de imagens (`yolo11n-cls.pt`). O treinamento foi conduzido por 25 √©pocas com batch size 16 e tendo como otimizador, o Adam. A principal m√©trica de desempenho utilizada foi a acur√°cia sobre os conjuntos de valida√ß√£o e teste.

Para realizar o treinamento, foi usado o ambiente de execu√ß√£o do Google Colab, com acelera√ß√£o por GPU (Tesla T4)	 e a biblioteca PyTorch integrada √† interface da Ultralytics.

## üìä Resultados
Ao final do treinamento com o modelo YOLOv11, foram obtidos resultados satisfat√≥rios quanto ao desempenho da aplica√ß√£o com a taxa de erro residual minima. Conforme mostra a figura a seguir, √© observado a evolu√ß√£o das curvas de loss e acur√°cia ao longo das √©pocas. E percebe-se que o **loss de treino** apresentou uma queda consistente e o de valida√ß√£o caiu rapidamente nas primeiras √©pocas, estabilizando-se pr√≥ximo a zero. E em rela√ß√£o a **acur√°cia top-1**, teve uma evolu√ß√£o positiva, com valores superiores a 97%, e a **acur√°cia top-5** permaneceu constante em 100%.

<div align="center"> <img src="assets/train/results.png" alt="Curvas de Acur√°cia e Perda" width="400"/> </div>

Com isso, a acur√°cia do treinamento √© 98,7%. Para avaliar o desempenho do modelo ap√≥s o treinamento, foi fornecido a rede neural um conjunto de imagens testes, e obtido a matriz de confus√£o que demonstra a seguinte permformance.
<div align="center"> <img src="assets/test/confusion_matrix.png" alt="Matriz de Confus√£o" width="400"/> </div>

A partir dessa matriz nota-se que o modelo classificou corretamente 114 de 115 imagens da classe fire, e 36 das 38, non_fire. Isso demonstra uma acur√°cia de aproximadamente de 99,3%. Esses resultados indicam uma excelente capacidade de generaliza√ß√£o para imagens nunca vistas. E considerando que a divis√£o do dataset foi aleat√≥ria, o modelo se mostrou robusto, com √≥timo desempenho em detectar imagens com fogo mesmo em cen√°rios variados de ilumina√ß√£o e perspectiva.

Notou-se um caso em que a rede erra na classifica√ß√£o a demonstrada abaixo.

## Conclus√£o
Os resultados alcan√ßados foram poss√≠veis devido a utiliza√ß√£o do YOLOv11 na tarefa de classifica√ß√£o aliado ao otimizador Adam, permitindo encontrar um desempenho robusto sem a necessidade de arquiteturas complexas ou alto custo computacional. Em trabalhos futuros, pode-se expandir essa aplica√ß√£o para a detec√ß√£o localizada de focos de inc√™ndio em tempo real (objeto + bounding box), incorporando varia√ß√µes clim√°ticas e contextos diversos. 

