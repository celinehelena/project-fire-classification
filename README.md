# üî• Classifica√ß√£o Bin√°ria da Presen√ßa de Fogo em Imagens com Yolov11
Este reposit√≥rio tem por objetivo apresentar um projeto desenvolvido para a disciplina de gradua√ß√£o, Vis√£o Computacional, que consiste em aborda uma solu√ß√£o para a classifica√ß√£o da presen√ßa de fogo em imagens usando o YOLOv11.
<div align="center">
<img src="assets/teste/val_batch1_pred.jpg" alt="Resultado" width="450"/>
  <p><strong>Figura 1:</strong> Resultado da classifica√ß√£o pelo Yolo.</p>
</div>

## üìÅ Estrutura do projeto
```
project-fire-classify/
‚îú‚îÄ‚îÄ assets/ # Recursos auxiliares, como imagens para documenta√ß√£o
|   ‚îú‚îÄ‚îÄ teste/ # Resultados obtidos do testes
|   ‚îú‚îÄ‚îÄ train/ # Resultados obtidos do treinamento
|   ‚îú‚îÄ‚îÄ amosta_dataset.jpeg  # Amostra visual de imagens presentes no dataset
|   ‚îú‚îÄ‚îÄ comparation_matrix.png  # Imagem da matriz de compara√ß√£o entre teste e treinamento
|   ‚îú‚îÄ‚îÄ distribution_dataset.png  # Gr√°fico de distribui√ß√£o das classes no dataset
|   ‚îú‚îÄ‚îÄ erro_classifity.jpeg  # Exemplos de erro de classifica√ß√£o cometido pelo modelo
‚îú‚îÄ‚îÄ weights/  # Pesos finais gerados ap√≥s o treinamento da rede
‚îú‚îÄ‚îÄ LICENSE  # Licen√ßa de uso do projeto
‚îú‚îÄ‚îÄ README.md  # Documenta√ß√£o principal do projeto
‚îî‚îÄ‚îÄ train_yolo.ipynb  # Notebook respons√°vel pelo treinamento do modelo YOLOv11
````

## üìå Introdu√ß√£o
Em 2024, o Brasil registrou 278,3 mil focos de inc√™ndio, segundo o Inpe, que representa um aumento de 46,5%, em rela√ß√£o ao ano anterior. De modo que a detec√ß√£o precoce desses principios de inc√™ndio √© essencia para uma resposta r√°pida e eficaz, minimizando os danos causados. Para que isso aconte√ßa √© necess√°rio um monitoramento autom√°tico de inc√™ndio por meio de imagens. Nesse contexto, a aplica√ß√£o de solu√ß√µes baseadas em vis√£o computacional e aprendizado de m√°quina tem se mostrado eficiente para a detec√ß√£o precoce de focos de inc√™ndio em imagens capturadas por sat√©lites, c√¢meras fixas ou drones.

Este trabalho apresenta o desenvolvimento de um aplica√ß√£o de classifica√ß√£o de imagens que identifica a presen√ßa ou aus√™ncia de fogo, utilizando a arquitetura YOLOv11, um modelo especifico para classifica√ß√£o de imagens. O objetivo √© treinar esse modelo para classificar imagens em duas categorias: "fire" e "non_fire".

## ‚öôÔ∏è Metodologia
Para a realiza√ß√£o da tarefa de classifica√ß√£o bin√°ria de imagens, foi utilizado o [Fire Dataset](https://www.kaggle.com/datasets/phylake1337/fire-dataset), disponibilizado na plataforma Kaggle. O conjunto de dados √© composto por 999 imagens divididas em duas classes: `fire_images` (imagens contendo fogo) e `non_fire_images` (imagens sem ocorr√™ncia de fogo). As imagens contemplam uma ampla gama de cen√°rios, incluindo ambientes naturais (como florestas) e urbanos (como edifica√ß√µes, resid√™ncias, ve√≠culos e rodovias), o que contribui para uma maior robustez na generaliza√ß√£o do modelo.
A seguir, √© exibida uma amostra representativa do dataset, gerada por um script automatizado respons√°vel por selecionar imagens aleat√≥rias da base.
<div align="center">
<img src="assets/amosta_dataset.jpeg" alt="Amostra do Dataset" width="500"/>
  <p><strong>Figura 2:</strong> Amostra de imagens do dataset.</p>
</div>

### üóÇÔ∏è Distribui√ß√£o do Dataset
O processo teve in√≠cio com o download da base de dados e sua reorganiza√ß√£o no formato exigido pelo YOLO, com as imagens distribu√≠das em subpastas para treinamento, valida√ß√£o e teste. O conjunto original foi, ent√£o, dividido aleatoriamente em tr√™s subconjuntos: treinamento (70%), valida√ß√£o (15%) e teste (15%). O gr√°fico abaixo ilustra essa divis√£o:
<div align="center">
<img src="assets/distribution_dataset.png" alt="Gr√°fico de Distribui√ß√£o das Imagens no Dataset" width="450"/>
  <p><strong>Figura 3:</strong> Gr√°fico de Distribui√ß√£o das Imagens do Dataset.</p>
</div>

A divis√£o foi realizada com aux√≠lio de um script que aloca aleatoriamente as imagens entre os tr√™s subconjuntos. A distribui√ß√£o final das imagens ficou da seguinte forma:
<div align="center">
  
| Classe     | Treino | Valida√ß√£o | Teste |
|------------|--------|-----------|-------|
| `fire`     | 528    | 113       | 114   |
| `non_fire` | 170    | 36        | 38    |

<p><strong>Tabela 1:</strong> Particionamento do dateset nos subconjuntos.</p>

</div>

### Pr√©-Processamento de dados

As imagens passaram por um processo de pr√©-processamento, sendo automaticamente redimensionadas para 640√ó640 pixels, conforme o par√¢metro `imgsz`, e normalizadas com os valores de pixel convertidos para o intervalo `[0, 1]`, como exigido pelo pipeline da Ultralytics. T√©cnicas leves de data augmentation foram aplicadas automaticamente, incluindo espelhamento horizontal aleat√≥rio, corte e altera√ß√µes de brilho e contraste, contribuindo para uma melhor capacidade de generaliza√ß√£o do modelo.

Inclui tamb√©m no pr√©-processamente a etapa mencionada anteriormente, particionamento do conjunto de dados em treinamento (70%), valida√ß√£o (15%) e teste (15%).

### Arquitetura do modelo
A arquitetura selecionada para a tarefa de classifica√ß√£o de imagens foi a YOLOv11 (You Only Look Once, vers√£o 11), com √™nfase no modelo `yolo11n-cls.pt`, previamente treinado para tarefas de classifica√ß√£o. Esta vers√£o √© adaptada para classifica√ß√£o pura e mostra-se adequada para cen√°rios com dados limitados e distribui√ß√£o desbalanceada entre as classes.

A tarefa desenvolvida consistiu em uma classifica√ß√£o bin√°ria, com o objetivo de identificar a presen√ßa (fire) ou aus√™ncia (non_fire) de fogo em imagens. O modelo foi refinado para capturar padr√µes visuais caracter√≠sticos de inc√™ndios, como a presen√ßa de chamas, colora√ß√£o avermelhada e fuma√ßa.

### **Ferramentas e Bibliotecas Utilizadas**

O desenvolvimento e a execu√ß√£o do projeto foram realizados com o suporte das seguintes ferramentas e bibliotecas:
* **YOLOv11 (Ultralytics):** Framework utilizado para implementa√ß√£o da arquitetura e gerenciamento da pipeline de treinamento;
* **PyTorch:** Biblioteca de aprendizado profundo empregada na modelagem e execu√ß√£o da rede neural;
* **Python 3.10:** Linguagem de programa√ß√£o principal utilizada no projeto;
* **Google Colab (GPU Tesla T4):** Ambiente de desenvolvimento com suporte √† acelera√ß√£o por GPU, facilitando o treinamento do modelo;
* **Matplotlib**: Bibliotecas para visualiza√ß√£o de dados e an√°lise gr√°fica dos resultados.
  
Essa infraestrutura possibilitou um fluxo de trabalho eficiente e reprodut√≠vel, al√©m de oferecer suporte para o monitoramento detalhado do desempenho do modelo.

### Treinamento e Avalia√ß√£o do Modelo

O treinamento foi conduzido usando os seguintes principais par√¢metros:
* `model='yolo11n-cls.pt'` ‚Äì Modelo base pr√©-treinado para classifica√ß√£o;
* `data=data.yaml` ‚Äì Arquivo de configura√ß√£o com caminhos para os conjuntos train, val e test;
* `epochs=25` ‚Äì N√∫mero total de √©pocas para treinamento;
* `batch=16` ‚Äì Tamanho do lote (batch size);
* `imgsz=640` ‚Äì Resolu√ß√£o das imagens (640x640 pixels);

Durante o treinamento, o modelo foi capaz de aprender rapidamente os padr√µes visuais relacionados √† presen√ßa de fogo, com melhora significativa das m√©tricas j√° nas primeiras √©pocas. 
<div align="center"> 
  <img src="assets/train/train_batch0.jpg" alt="Imagens da etapa de treinamento" width="500"/> 
  <p><strong>Figura 4:</strong> Imagens da etapa de treinamento.</p>
</div>

Ap√≥s o treinamento, a performance do modelo foi avaliada automaticamente com base nos seguintes indicadores:

* **Loss** ‚Äì Perda (erro) da predi√ß√£o ao longo das √©pocas;
* **Top-1 Accuracy** ‚Äì Percentual de acertos considerando a classe mais prov√°vel;
* **Top-5 Accuracy** ‚Äì Percentual de acertos considerando as 5 classes mais prov√°veis (embora a tarefa seja bin√°ria);
* **Confusion Matrix** ‚Äì Representa√ß√£o visual dos acertos e erros por classe.

Al√©m disso, o modelo foi testado sobre o conjunto separado de imagens (`test`) para avaliar sua capacidade de generaliza√ß√£o, e os erros cometidos foram analisados individualmente, com imagens incorretamente classificadas sendo exibidas para an√°lise qualitativa.

## üìä Resultados e Discuss√µes
Ao final do treinamento, o modelo **YOLOv11** apresentou desempenho satisfat√≥rio, com taxa de erro residual m√≠nima. A figura a seguir mostra a evolu√ß√£o das curvas de loss e acur√°cia ao longo das √©pocas. Nota-se que o **loss** de treino teve uma queda consistente, enquanto o de valida√ß√£o caiu rapidamente nas primeiras √©pocas e estabilizou-se pr√≥ximo de zero. J√° a **acur√°cia top-1** evoluiu positivamente, superando 97%, enquanto a **acur√°cia top-5** manteve-se constante em 100%.

<div align="center"> 
  <img src="assets/train/results.png" alt="Curvas de Acur√°cia e Perda" width="400"/> 
  <p><strong>Figura 5:</strong> Gr√°ficos das Curvas de Acur√°cia e Perda</p>
</div>

A acur√°cia final no conjunto de treinamento foi de **98,7%**. Para avaliar o desempenho ap√≥s o treinamento, a rede foi testada com o conjunto de teste, e a matriz de confus√£o obtida demonstra a seguinte performance:
<div align="center"> 
  <img src="assets/teste/confusion_matrix.png" alt="Matriz de Confus√£o" width="500"/> 
  <p><strong>Figura 6:</strong> Matriz de confus√£o do teste</p>
</div>

A partir da matriz, observa-se que o modelo classificou corretamente 110 de 114 imagens da classe `fire` e 34 de 38 da classe `non_fire`, o que corresponde a uma acur√°cia de aproximadamente **94,7%**. Esses resultados indicam uma excelente capacidade de generaliza√ß√£o para imagens n√£o vistas anteriormente. Considerando a divis√£o aleat√≥ria do dataset, o modelo mostrou-se robusto, com √≥timo desempenho mesmo em cen√°rios variados de ilumina√ß√£o e perspectiva.

Al√©m disso, foi realizada uma compara√ß√£o entre as matrizes de confus√£o dos conjuntos de treinamento e teste, como mostrado a seguir:
<div align="center"> 
  <img src="assets/comparation_matrix.png" alt="Comparacao entre matrizes" width="850"/> 
  <p><strong>Figura 7: </strong> Compara√ß√£o entre as Matrizes de confus√£o</p>
</div>

Na fase de treinamento:

* `fire` corretamente identificado: 111;
* `non_fire` corretamente identificado: 36;
* Falsos positivos (`non_fire` previsto como `fire`): 2.

Na fase de teste:

* `fire` corretamente identificado: 110;
* `non_fire` corretamente identificado: 34;
* Falsos positivos: 4;
* Falsos negativos: 4.

A an√°lise mostra que o modelo manteve desempenho semelhante entre as fases, com uma leve oscila√ß√£o nos falsos positivos e falsos negativos. A aus√™ncia de predi√ß√µes para a classe background em ambas as fases sugere a possibilidade de reavaliar a representa√ß√£o dessa categoria nas anota√ß√µes ou sua real necessidade no modelo.

A seguir, √© apresentada uma imagem com alguns dos resultados de classifica√ß√£o do modelo:

<div align="center"> 
  <img src="assets/teste/val_batch0_pred.jpg" alt="Predi√ß√µes em imagens reais" width="450"/> 
  <p><strong>Figura 8: </strong> Predi√ß√µes em imagens reais</p>
</div>

Alguns casos de erro de classifica√ß√£o foram identificados, como mostrado na figura 9.

<div align="center"> 
  <img src="assets/erro_classifity.jpeg" alt="Erro de classifica√ß√£o" width="800"/> 
  <p><strong>Figura 9: </strong> Erro de classifica√ß√£o</p>
</div>

Ao observar as imagens, nota-se que os erros de classifica√ß√£o ocorreram principalmente em dois contextos:

* Falsos negativos (imagens de fogo classificadas como "non_fire"): muitas dessas imagens apresentam fuma√ßa densa, por√©m com focos de chamas pouco vis√≠veis, o que pode ter confundido o modelo. Al√©m disso, a presen√ßa de vegeta√ß√£o densa ou nebulosidade pode ter mascarado os ind√≠cios visuais de fogo.
* Falsos positivos (imagens sem fogo classificadas como "fire"): alguns exemplos mostram ilumina√ß√£o alaranjada ou avermelhada, que pode ter sido interpretada como ind√≠cio de fogo. Outros casos envolvem presen√ßa de troncos escurecidos ou neblina iluminada, elementos que se assemelham visualmente a fuma√ßa ou chamas, sobretudo se o modelo ainda apresenta sensibilidade a padr√µes de cor ou textura.

Esses resultados indicam que, embora o modelo YOLOv11 tenha apresentado excelente desempenho geral, ele ainda enfrenta desafios em ambientes com ambiguidade visual ou caracter√≠sticas visuais at√≠picas.

## Conclus√£o
Os resultados alcan√ßados foram poss√≠veis devido a utiliza√ß√£o do YOLOv11 na tarefa de classifica√ß√£o aliado ao otimizador Adam, permitindo encontrar um desempenho robusto sem a necessidade de arquiteturas complexas ou alto custo computacional. Em trabalhos futuros, pode-se expandir essa aplica√ß√£o para a detec√ß√£o localizada de focos de inc√™ndio em tempo real (objeto + bounding box), incorporando varia√ß√µes clim√°ticas e contextos diversos. 

## üìö Refer√™ncias

* Brasil registrou 278,3 mil focos de inc√™ndio em 2024, diz INPE. CNN Brasil, 19 de mar√ßo de 2024.
Dispon√≠vel em: https://www.cnnbrasil.com.br/nacional/brasil-registrou-2783-mil-focos-de-incendio-em-2024-diz-inpe

* Fire Detection Image Dataset. Kaggle ‚Äì Forest Fire Smoke Image Dataset. Dispon√≠vel em:
https://www.kaggle.com/datasets/syedmuhammadusmanshahid/fire-detection-image-dataset

* PyTorch ‚Äì An open source machine learning framework:
https://pytorch.org/

* YOLOv11 Classification. YOLOv11 - You Only Look Once (vers√£o de classifica√ß√£o). Reposit√≥rio oficial:
https://github.com/WongKinYiu/yolov11



