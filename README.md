# üî• Classifica√ß√£o Bin√°ria da Presen√ßa de Fogo em Imagens com Yolov11
Este reposit√≥rio tem por objetivo apresentar um projeto desenvolvido para a disciplina de gradua√ß√£o, Vis√£o Computacional, que consiste em aborda uma solu√ß√£o para a classifica√ß√£o da presen√ßa de fogo em imagens usando o YOLOv11.

## üìå Introdu√ß√£o
Em 2024, o Brasil registrou 278,3 mil focos de inc√™ndio, segundo o Inpe, que representa um aumento de 46,5%, em rela√ß√£o ao ano anterior. De modo que a detec√ß√£o precoce desses principios de inc√™ndio √© essencia para uma resposta r√°pida e eficaz, minimizando os danos causados. Para que isso aconte√ßa √© necess√°rio um monitoramento autom√°tico de inc√™ndio por meio de imagens. Nesse contexto, a aplica√ß√£o de solu√ß√µes baseadas em vis√£o computacional e aprendizado de m√°quina tem se mostrado eficiente para a detec√ß√£o precoce de focos de inc√™ndio em imagens capturadas por sat√©lites, c√¢meras fixas ou drones.

Este trabalho apresenta o desenvolvimento de um aplica√ß√£o de classifica√ß√£o de imagens que identifica a presen√ßa ou aus√™ncia de fogo, utilizando a arquitetura YOLOv11, um modelo especifico para classifica√ß√£o de imagens. O objetivo √© treinar esse modelo para classificar imagens em duas categorias: "fire" e "non_fire".

## ‚öôÔ∏è Desenvolvimento / T√©cnicas Utilizadas
Para a tarefa de classifica√ß√£o de imagens, foi utilizado o Fire Dataset, disponibilizado no Kaggle, contendo 999 imagens organizadas em duas categorias: `fire_images` e `non_fire_images`. O processo teve in√≠cio com o download da base de dados e sua reorganiza√ß√£o no formato exigido pelo YOLO, com as imagens distribu√≠das em subpastas para treinamento, valida√ß√£o e teste. O conjunto original foi, ent√£o, dividido aleatoriamente em tr√™s subconjuntos: treinamento (70%), valida√ß√£o (15%) e teste (15%). O gr√°fico abaixo ilustra essa divis√£o:
<p align="center">
<img src="assets/distribution_dataset_img.png" alt="Gr√°fico de Distribui√ß√£o das Imagens no Dataset" width="450"/>
</p>

A divis√£o foi realizada com aux√≠lio de um script que aloca aleatoriamente as imagens entre os tr√™s subconjuntos. A distribui√ß√£o final das imagens ficou da seguinte forma:

| Classe     | Treino | Valida√ß√£o | Teste |
|------------|--------|-----------|-------|
| `fire`     | 528    | 113       | 114   |
| `non_fire` | 170    | 36        | 38    |

As imagens passaram por um processo de pr√©-processamento, sendo automaticamente redimensionadas para 640√ó640 pixels, conforme o par√¢metro `imgsz`, e normalizadas com os valores de pixel convertidos para o intervalo `[0, 1]`, como exigido pelo pipeline da Ultralytics. T√©cnicas leves de data augmentation foram aplicadas automaticamente, incluindo espelhamento horizontal aleat√≥rio, corte e altera√ß√µes de brilho e contraste, contribuindo para uma melhor capacidade de generaliza√ß√£o do modelo.

O modelo utilizado foi a arquitetura YOLOv11, na vers√£o pr√©-treinada para tarefas de classifica√ß√£o (`yolo11n-cls.pt`). O treinamento foi conduzido por 25 √©pocas, com batch size 16 e uso do otimizador `Adam`. A principal m√©trica de desempenho adotada foi a acur√°cia nos conjuntos de valida√ß√£o e teste.

O treinamento foi realizado no ambiente Google Colab, com acelera√ß√£o por GPU (Tesla T4), utilizando a biblioteca PyTorch integrada √† interface da Ultralytics.

## üìä Resultados
Ao final do treinamento, o modelo **YOLOv11** apresentou desempenho satisfat√≥rio, com taxa de erro residual m√≠nima. A figura a seguir mostra a evolu√ß√£o das curvas de loss e acur√°cia ao longo das √©pocas. Nota-se que o **loss** de treino teve uma queda consistente, enquanto o de valida√ß√£o caiu rapidamente nas primeiras √©pocas e estabilizou-se pr√≥ximo de zero. J√° a **acur√°cia top-1** evoluiu positivamente, superando 97%, enquanto a **acur√°cia top-5** manteve-se constante em 100%.

<div align="center"> <img src="assets/train/results.png" alt="Curvas de Acur√°cia e Perda" width="400"/> </div>

A acur√°cia final no conjunto de treinamento foi de **98,7%**. Para avaliar o desempenho ap√≥s o treinamento, a rede foi testada com o conjunto de teste, e a matriz de confus√£o obtida demonstra a seguinte performance:
<div align="center"> <img src="assets/test/confusion_matrix.png" alt="Matriz de Confus√£o" width="400"/> </div>

A partir da matriz, observa-se que o modelo classificou corretamente 114 de 115 imagens da classe `fire` e 36 de 38 da classe `non_fire`, o que corresponde a uma acur√°cia de aproximadamente **99,3%**. Esses resultados indicam uma excelente capacidade de generaliza√ß√£o para imagens n√£o vistas anteriormente. Considerando a divis√£o aleat√≥ria do dataset, o modelo mostrou-se robusto, com √≥timo desempenho mesmo em cen√°rios variados de ilumina√ß√£o e perspectiva.

A seguir, √© apresentada uma imagem com alguns dos resultados de classifica√ß√£o do modelo:
<div align="center"> <img src="assets/test/confusion_matrix.png" alt="Matriz de Confus√£o" width="400"/> </div>
Foi identificado apenas um caso de erro de classifica√ß√£o, ilustrado na imagem abaixo.

## Conclus√£o
Os resultados alcan√ßados foram poss√≠veis devido a utiliza√ß√£o do YOLOv11 na tarefa de classifica√ß√£o aliado ao otimizador Adam, permitindo encontrar um desempenho robusto sem a necessidade de arquiteturas complexas ou alto custo computacional. Em trabalhos futuros, pode-se expandir essa aplica√ß√£o para a detec√ß√£o localizada de focos de inc√™ndio em tempo real (objeto + bounding box), incorporando varia√ß√µes clim√°ticas e contextos diversos. 

